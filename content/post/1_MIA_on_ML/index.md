---
title: Reading Note of the Paper "Membership Inference Attacks on Machine Learning - A Survey"
subtitle: 

# Summary for listings and search engines
summary: 

# Link this post with a project
projects: []

# Date published
date: '2023-6-17T00:00:00Z'

# Date updated
lastmod: '2023-6-17T00:00:00Z'

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: false

authors:
  - admin
---

## Abstract

Membership Inference Attack (MIA): to infer whether a data record was used to train a target model or not.

MIAs on ML (classification, generative, ...) models can directly lead to a privacy breach (i.e., infer privacy information from training data).

For e.g. via identifying the fact that a clinical record has been used to train a model associated with a certain disease, an attacker can infer that the owner of the clinical record has the disease with a high chance.

**Key Words**: privacy protection, MIA, differential privacy

Please click [here](https://yanyun-wangs-gitbook.gitbook.io/yanyun-wangs-gitbook/reading-notes-for-papers/reading-note-membership-inference-attacks-on-machine-learning-a-survey) to access the full content of the blog.


## Information of the Original Paper

