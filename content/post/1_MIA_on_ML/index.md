---
title: Reading Note of the Paper "Membership Inference Attacks on Machine Learning - A Survey"
subtitle: 

# Summary for listings and search engines
summary: 

# Link this post with a project
projects: []

# Date published
date: '2023-6-17T00:00:00Z'

# Date updated
lastmod: '2023-6-17T00:00:00Z'

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: false

authors:
  - admin
---


## Information of the Original Paper

```markdown
Hu, H., Salcic, Z., Sun, L., Dobbie, G., Yu, P. S., & Zhang, X. (2022). Membership inference attacks on machine learning: A survey. ACM Computing Surveys (CSUR), 54(11s), 1-37.
```



## Abstract

Membership Inference Attack (MIA): to infer whether a data record was used to train a target model or not.

MIAs on ML (classification, generative, etc.) models can directly lead to a privacy breach (i.e., infer privacy information from training data).

For e.g. via identifying the fact that a clinical record has been used to train a model associated with a certain disease, an attacker can infer that the owner of the clinical record has the disease with a high chance.

**Key Words**: privacy protection, MIA, differential privacy


## Access

Please click [here](https://yanyun-wangs-gitbook.gitbook.io/yanyun-wangs-gitbook/reading-notes-for-papers/reading-note-membership-inference-attacks-on-machine-learning-a-survey) to access the content of the blog from my Gitbook.

